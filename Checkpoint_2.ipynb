{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix,accuracy_score, precision_score, recall_score, f1_score\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('preprocessed datase.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>text_</th>\n",
       "      <th>review_length</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>vector_0</th>\n",
       "      <th>vector_1</th>\n",
       "      <th>vector_2</th>\n",
       "      <th>vector_3</th>\n",
       "      <th>vector_4</th>\n",
       "      <th>...</th>\n",
       "      <th>vector_290</th>\n",
       "      <th>vector_291</th>\n",
       "      <th>vector_292</th>\n",
       "      <th>vector_293</th>\n",
       "      <th>vector_294</th>\n",
       "      <th>vector_295</th>\n",
       "      <th>vector_296</th>\n",
       "      <th>vector_297</th>\n",
       "      <th>vector_298</th>\n",
       "      <th>vector_299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Love this!  Well made, sturdy, and very comfor...</td>\n",
       "      <td>75</td>\n",
       "      <td>love well made sturdy comfortable love itvery ...</td>\n",
       "      <td>0.009552</td>\n",
       "      <td>0.055578</td>\n",
       "      <td>-0.074036</td>\n",
       "      <td>-0.004832</td>\n",
       "      <td>-0.087739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.135590</td>\n",
       "      <td>0.035983</td>\n",
       "      <td>0.118541</td>\n",
       "      <td>0.009863</td>\n",
       "      <td>-0.006641</td>\n",
       "      <td>0.030139</td>\n",
       "      <td>-0.006002</td>\n",
       "      <td>-0.066576</td>\n",
       "      <td>0.032783</td>\n",
       "      <td>-0.117144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>love it, a great upgrade from the original.  I...</td>\n",
       "      <td>80</td>\n",
       "      <td>love great upgrade original mine couple year</td>\n",
       "      <td>0.024314</td>\n",
       "      <td>0.011938</td>\n",
       "      <td>-0.050561</td>\n",
       "      <td>-0.000509</td>\n",
       "      <td>-0.047107</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065640</td>\n",
       "      <td>0.011398</td>\n",
       "      <td>0.079855</td>\n",
       "      <td>-0.008035</td>\n",
       "      <td>-0.018000</td>\n",
       "      <td>-0.024986</td>\n",
       "      <td>-0.004174</td>\n",
       "      <td>-0.053297</td>\n",
       "      <td>0.013269</td>\n",
       "      <td>-0.065177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>This pillow saved my back. I love the look and...</td>\n",
       "      <td>67</td>\n",
       "      <td>pillow saved back love look feel pillow</td>\n",
       "      <td>0.037266</td>\n",
       "      <td>0.021903</td>\n",
       "      <td>-0.104903</td>\n",
       "      <td>-0.024621</td>\n",
       "      <td>-0.121138</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136369</td>\n",
       "      <td>0.025341</td>\n",
       "      <td>0.071049</td>\n",
       "      <td>-0.008753</td>\n",
       "      <td>0.033459</td>\n",
       "      <td>0.084169</td>\n",
       "      <td>0.008969</td>\n",
       "      <td>-0.039396</td>\n",
       "      <td>0.084630</td>\n",
       "      <td>-0.111436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Missing information on how to use it, but it i...</td>\n",
       "      <td>81</td>\n",
       "      <td>missing information use great product price</td>\n",
       "      <td>0.038293</td>\n",
       "      <td>-0.021084</td>\n",
       "      <td>-0.034790</td>\n",
       "      <td>0.013776</td>\n",
       "      <td>-0.031484</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064170</td>\n",
       "      <td>0.037570</td>\n",
       "      <td>0.096194</td>\n",
       "      <td>-0.001511</td>\n",
       "      <td>0.026777</td>\n",
       "      <td>-0.060727</td>\n",
       "      <td>-0.007324</td>\n",
       "      <td>-0.053665</td>\n",
       "      <td>0.042030</td>\n",
       "      <td>-0.102379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Very nice set. Good quality. We have had the s...</td>\n",
       "      <td>85</td>\n",
       "      <td>nice set good quality set two month not</td>\n",
       "      <td>-0.018134</td>\n",
       "      <td>0.016582</td>\n",
       "      <td>0.006793</td>\n",
       "      <td>0.012251</td>\n",
       "      <td>-0.033542</td>\n",
       "      <td>...</td>\n",
       "      <td>0.127616</td>\n",
       "      <td>0.023219</td>\n",
       "      <td>0.063599</td>\n",
       "      <td>-0.049727</td>\n",
       "      <td>0.007967</td>\n",
       "      <td>-0.039801</td>\n",
       "      <td>-0.004324</td>\n",
       "      <td>-0.021565</td>\n",
       "      <td>0.060416</td>\n",
       "      <td>-0.048606</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 305 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating  label                                              text_  \\\n",
       "0       5      1  Love this!  Well made, sturdy, and very comfor...   \n",
       "1       5      1  love it, a great upgrade from the original.  I...   \n",
       "2       5      1  This pillow saved my back. I love the look and...   \n",
       "3       1      1  Missing information on how to use it, but it i...   \n",
       "4       5      1  Very nice set. Good quality. We have had the s...   \n",
       "\n",
       "   review_length                                       cleaned_text  vector_0  \\\n",
       "0             75  love well made sturdy comfortable love itvery ...  0.009552   \n",
       "1             80       love great upgrade original mine couple year  0.024314   \n",
       "2             67            pillow saved back love look feel pillow  0.037266   \n",
       "3             81        missing information use great product price  0.038293   \n",
       "4             85            nice set good quality set two month not -0.018134   \n",
       "\n",
       "   vector_1  vector_2  vector_3  vector_4  ...  vector_290  vector_291  \\\n",
       "0  0.055578 -0.074036 -0.004832 -0.087739  ...    0.135590    0.035983   \n",
       "1  0.011938 -0.050561 -0.000509 -0.047107  ...    0.065640    0.011398   \n",
       "2  0.021903 -0.104903 -0.024621 -0.121138  ...    0.136369    0.025341   \n",
       "3 -0.021084 -0.034790  0.013776 -0.031484  ...    0.064170    0.037570   \n",
       "4  0.016582  0.006793  0.012251 -0.033542  ...    0.127616    0.023219   \n",
       "\n",
       "   vector_292  vector_293  vector_294  vector_295  vector_296  vector_297  \\\n",
       "0    0.118541    0.009863   -0.006641    0.030139   -0.006002   -0.066576   \n",
       "1    0.079855   -0.008035   -0.018000   -0.024986   -0.004174   -0.053297   \n",
       "2    0.071049   -0.008753    0.033459    0.084169    0.008969   -0.039396   \n",
       "3    0.096194   -0.001511    0.026777   -0.060727   -0.007324   -0.053665   \n",
       "4    0.063599   -0.049727    0.007967   -0.039801   -0.004324   -0.021565   \n",
       "\n",
       "   vector_298  vector_299  \n",
       "0    0.032783   -0.117144  \n",
       "1    0.013269   -0.065177  \n",
       "2    0.084630   -0.111436  \n",
       "3    0.042030   -0.102379  \n",
       "4    0.060416   -0.048606  \n",
       "\n",
       "[5 rows x 305 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Spliting the dataset into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['label', 'text_', 'cleaned_text'], axis=1)\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "pipelines = {\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'SVM': SVC(random_state=42,probability=True),\n",
    "    'Logistic Regression': LogisticRegression(random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating each model’s performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training and evaluating Random Forest...\n",
      "\n",
      "Accuracy: 0.6888\n",
      "Precision: 0.6905\n",
      "Recall: 0.6888\n",
      "F1 Score: 0.6883\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2636 1438]\n",
      " [1078 2932]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.65      0.68      4074\n",
      "           1       0.67      0.73      0.70      4010\n",
      "\n",
      "    accuracy                           0.69      8084\n",
      "   macro avg       0.69      0.69      0.69      8084\n",
      "weighted avg       0.69      0.69      0.69      8084\n",
      "\n",
      "Model saved as Random_Forest_model.pkl\n",
      "\n",
      "Training and evaluating SVM...\n",
      "\n",
      "Accuracy: 0.7006\n",
      "Precision: 0.7009\n",
      "Recall: 0.7006\n",
      "F1 Score: 0.7006\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2799 1275]\n",
      " [1145 2865]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.69      0.70      4074\n",
      "           1       0.69      0.71      0.70      4010\n",
      "\n",
      "    accuracy                           0.70      8084\n",
      "   macro avg       0.70      0.70      0.70      8084\n",
      "weighted avg       0.70      0.70      0.70      8084\n",
      "\n",
      "Model saved as SVM_model.pkl\n",
      "\n",
      "Training and evaluating Logistic Regression...\n",
      "\n",
      "Accuracy: 0.6212\n",
      "Precision: 0.6212\n",
      "Recall: 0.6212\n",
      "F1 Score: 0.6212\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2580 1494]\n",
      " [1568 2442]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.63      0.63      4074\n",
      "           1       0.62      0.61      0.61      4010\n",
      "\n",
      "    accuracy                           0.62      8084\n",
      "   macro avg       0.62      0.62      0.62      8084\n",
      "weighted avg       0.62      0.62      0.62      8084\n",
      "\n",
      "Model saved as Logistic_Regression_model.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "best_model = None\n",
    "best_performance = None\n",
    "\n",
    "for model_name, model in pipelines.items():\n",
    "    print(f\"\\nTraining and evaluating {model_name}...\")\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    print(f\"\\nAccuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    \n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    model_filename = f\"{model_name.replace(' ', '_')}_model.pkl\"\n",
    "    joblib.dump(model, model_filename)\n",
    "    print(f\"Model saved as {model_filename}\")  \n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_model = joblib.load('Random_Forest_model.pkl')\n",
    "svm_model = joblib.load('SVM_model.pkl')\n",
    "logistic_regression_model = joblib.load('Logistic_Regression_model.pkl')\n",
    "\n",
    "\n",
    "rf_predictions = random_forest_model.predict(X_test)\n",
    "svm_predictions = svm_model.predict(X_test)\n",
    "logistic_predictions = logistic_regression_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Model Predictions:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted by SVM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33075</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16852</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24930</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29281</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4990</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6860</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24467</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16177</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1487</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13713</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Actual  Predicted by SVM\n",
       "33075       1                 1\n",
       "16852       1                 0\n",
       "24930       0                 0\n",
       "29281       1                 1\n",
       "4990        0                 1\n",
       "6860        1                 1\n",
       "24467       1                 1\n",
       "16177       1                 1\n",
       "1487        1                 0\n",
       "13713       0                 1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_df_SVM = pd.DataFrame({\n",
    "    'Actual': y_test[:10],\n",
    "    'Predicted by SVM': svm_predictions[:10]\n",
    "})\n",
    "print(\"SVM Model Predictions:\")\n",
    "comparison_df_SVM"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
