{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "xpLXUSLrVm6f"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "import joblib\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzlNsX5dchgU"
      },
      "source": [
        "### **Load the Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "S2eZe_QsWC6H"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('preprocessed datase.csv')       "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "gAixtoGMXQKm",
        "outputId": "9ba96645-5a5f-4643-de4a-22531058b02a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rating</th>\n",
              "      <th>label</th>\n",
              "      <th>text_</th>\n",
              "      <th>review_length</th>\n",
              "      <th>cleaned_text</th>\n",
              "      <th>x</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>Love this!  Well made, sturdy, and very comfor...</td>\n",
              "      <td>75</td>\n",
              "      <td>love well made sturdy comfortable love itvery ...</td>\n",
              "      <td>[0.         0.         0.         0.         0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>love it, a great upgrade from the original.  I...</td>\n",
              "      <td>80</td>\n",
              "      <td>love great upgrade original mine couple year</td>\n",
              "      <td>[0.         0.         0.         0.         0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>This pillow saved my back. I love the look and...</td>\n",
              "      <td>67</td>\n",
              "      <td>pillow saved back love look feel pillow</td>\n",
              "      <td>[0.         0.         0.         0.         0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Missing information on how to use it, but it i...</td>\n",
              "      <td>81</td>\n",
              "      <td>missing information use great product price</td>\n",
              "      <td>[0.         0.         0.         0.         0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>Very nice set. Good quality. We have had the s...</td>\n",
              "      <td>85</td>\n",
              "      <td>nice set good quality set two month not</td>\n",
              "      <td>[0.         0.         0.         0.         0...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   rating  label                                              text_  \\\n",
              "0       5      1  Love this!  Well made, sturdy, and very comfor...   \n",
              "1       5      1  love it, a great upgrade from the original.  I...   \n",
              "2       5      1  This pillow saved my back. I love the look and...   \n",
              "3       1      1  Missing information on how to use it, but it i...   \n",
              "4       5      1  Very nice set. Good quality. We have had the s...   \n",
              "\n",
              "   review_length                                       cleaned_text  \\\n",
              "0             75  love well made sturdy comfortable love itvery ...   \n",
              "1             80       love great upgrade original mine couple year   \n",
              "2             67            pillow saved back love look feel pillow   \n",
              "3             81        missing information use great product price   \n",
              "4             85            nice set good quality set two month not   \n",
              "\n",
              "                                                   x  \n",
              "0  [0.         0.         0.         0.         0...  \n",
              "1  [0.         0.         0.         0.         0...  \n",
              "2  [0.         0.         0.         0.         0...  \n",
              "3  [0.         0.         0.         0.         0...  \n",
              "4  [0.         0.         0.         0.         0...  "
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = df.drop(columns=['cleaned_text', 'text_'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rating</th>\n",
              "      <th>label</th>\n",
              "      <th>review_length</th>\n",
              "      <th>x</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>75</td>\n",
              "      <td>[0.         0.         0.         0.         0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>80</td>\n",
              "      <td>[0.         0.         0.         0.         0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>67</td>\n",
              "      <td>[0.         0.         0.         0.         0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>81</td>\n",
              "      <td>[0.         0.         0.         0.         0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>[0.         0.         0.         0.         0...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   rating  label  review_length  \\\n",
              "0       5      1             75   \n",
              "1       5      1             80   \n",
              "2       5      1             67   \n",
              "3       1      1             81   \n",
              "4       5      1             85   \n",
              "\n",
              "                                                   x  \n",
              "0  [0.         0.         0.         0.         0...  \n",
              "1  [0.         0.         0.         0.         0...  \n",
              "2  [0.         0.         0.         0.         0...  \n",
              "3  [0.         0.         0.         0.         0...  \n",
              "4  [0.         0.         0.         0.         0...  "
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "THneJGy9XRSd"
      },
      "outputs": [],
      "source": [
        "X = df['x']\n",
        "y = df['label'] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model training with pipelines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "could not convert string to float: '[0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.456994   0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.44345971 0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.32411611 0.         0.51226219 0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.2549067  0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.33174833\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.22803903 0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.        ]'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[58], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Random Forest Model\u001b[39;00m\n\u001b[0;32m      2\u001b[0m rf_pipeline \u001b[38;5;241m=\u001b[39m Pipeline([\n\u001b[0;32m      3\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscaler\u001b[39m\u001b[38;5;124m'\u001b[39m, StandardScaler()), \n\u001b[0;32m      4\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m'\u001b[39m, RandomForestClassifier())\n\u001b[0;32m      5\u001b[0m ])\n\u001b[1;32m----> 6\u001b[0m \u001b[43mrf_pipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Support Vector Machine Model\u001b[39;00m\n\u001b[0;32m      9\u001b[0m svc_pipeline \u001b[38;5;241m=\u001b[39m Pipeline([\n\u001b[0;32m     10\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscaler\u001b[39m\u001b[38;5;124m'\u001b[39m, StandardScaler()), \n\u001b[0;32m     11\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msvc\u001b[39m\u001b[38;5;124m'\u001b[39m, SVC())\n\u001b[0;32m     12\u001b[0m ])\n",
            "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sklearn\\pipeline.py:469\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    426\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model.\u001b[39;00m\n\u001b[0;32m    427\u001b[0m \n\u001b[0;32m    428\u001b[0m \u001b[38;5;124;03mFit all the transformers one after the other and sequentially transform the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;124;03m    Pipeline with fitted steps.\u001b[39;00m\n\u001b[0;32m    467\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    468\u001b[0m routed_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_method_params(method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m, props\u001b[38;5;241m=\u001b[39mparams)\n\u001b[1;32m--> 469\u001b[0m Xt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    470\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[0;32m    471\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
            "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sklearn\\pipeline.py:406\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[1;34m(self, X, y, routed_params)\u001b[0m\n\u001b[0;32m    404\u001b[0m     cloned_transformer \u001b[38;5;241m=\u001b[39m clone(transformer)\n\u001b[0;32m    405\u001b[0m \u001b[38;5;66;03m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[1;32m--> 406\u001b[0m X, fitted_transformer \u001b[38;5;241m=\u001b[39m \u001b[43mfit_transform_one_cached\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    407\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcloned_transformer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    408\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    409\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    410\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    411\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage_clsname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPipeline\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    412\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_idx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    413\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    414\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    415\u001b[0m \u001b[38;5;66;03m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;66;03m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;66;03m# from the cache.\u001b[39;00m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[step_idx] \u001b[38;5;241m=\u001b[39m (name, fitted_transformer)\n",
            "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\joblib\\memory.py:312\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 312\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sklearn\\pipeline.py:1310\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, params)\u001b[0m\n\u001b[0;32m   1308\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[0;32m   1309\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1310\u001b[0m         res \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfit_transform\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1311\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1312\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}))\u001b[38;5;241m.\u001b[39mtransform(\n\u001b[0;32m   1313\u001b[0m             X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransform\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\n\u001b[0;32m   1314\u001b[0m         )\n",
            "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:313\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 313\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    314\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    315\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    316\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    317\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    318\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    319\u001b[0m         )\n",
            "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sklearn\\base.py:1101\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m   1098\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1100\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m-> 1101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(X)\n",
            "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:878\u001b[0m, in \u001b[0;36mStandardScaler.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[1;32m--> 878\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:914\u001b[0m, in \u001b[0;36mStandardScaler.partial_fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    882\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Online computation of mean and std on X for later scaling.\u001b[39;00m\n\u001b[0;32m    883\u001b[0m \n\u001b[0;32m    884\u001b[0m \u001b[38;5;124;03mAll of X is processed as a single batch. This is intended for cases\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    911\u001b[0m \u001b[38;5;124;03m    Fitted scaler.\u001b[39;00m\n\u001b[0;32m    912\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    913\u001b[0m first_call \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_samples_seen_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 914\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    919\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfirst_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    920\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    921\u001b[0m n_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    923\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sklearn\\base.py:633\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    631\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 633\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    635\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
            "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:1012\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1010\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1011\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1012\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1013\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m   1014\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1015\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m   1016\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:751\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[0;32m    749\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 751\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    753\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[0;32m    754\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
            "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\core\\series.py:1031\u001b[0m, in \u001b[0;36mSeries.__array__\u001b[1;34m(self, dtype, copy)\u001b[0m\n\u001b[0;32m    981\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    982\u001b[0m \u001b[38;5;124;03mReturn the values as a NumPy array.\u001b[39;00m\n\u001b[0;32m    983\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1028\u001b[0m \u001b[38;5;124;03m      dtype='datetime64[ns]')\u001b[39;00m\n\u001b[0;32m   1029\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1030\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m-> 1031\u001b[0m arr \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1032\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m using_copy_on_write() \u001b[38;5;129;01mand\u001b[39;00m astype_is_view(values\u001b[38;5;241m.\u001b[39mdtype, arr\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[0;32m   1033\u001b[0m     arr \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mview()\n",
            "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '[0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.456994   0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.44345971 0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.32411611 0.         0.51226219 0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.2549067  0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.33174833\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.22803903 0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.         0.         0.\\n 0.         0.         0.         0.        ]'"
          ]
        }
      ],
      "source": [
        "# Random Forest Model\n",
        "rf_pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()), \n",
        "    ('rf', RandomForestClassifier())\n",
        "])\n",
        "rf_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Support Vector Machine Model\n",
        "svc_pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()), \n",
        "    ('svc', SVC())\n",
        "])\n",
        "svc_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Logistic Regression Model\n",
        "logreg_pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()), \n",
        "    ('logreg', LogisticRegression())\n",
        "])\n",
        "logreg_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Model evaluation\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    y_pred = model.predict(X_test)\n",
        "    return {\n",
        "        'accuracy': accuracy_score(y_test, y_pred),\n",
        "        'precision': precision_score(y_test, y_pred),\n",
        "        'recall': recall_score(y_test, y_pred),\n",
        "        'f1_score': f1_score(y_test, y_pred)\n",
        "    }\n",
        "\n",
        "rf_metrics = evaluate_model(rf_pipeline, X_test, y_test)\n",
        "svc_metrics = evaluate_model(svc_pipeline, X_test, y_test)\n",
        "logreg_metrics = evaluate_model(logreg_pipeline, X_test, y_test)\n",
        "\n",
        "print(f'Random Forest Metrics: {rf_metrics}')\n",
        "print(f'SVC Metrics: {svc_metrics}')\n",
        "print(f'Logistic Regression Metrics: {logreg_metrics}')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
